{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 원티드 프리온보딩 AI/ML 코스: 수강생 선발과제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 문제 1) Tokenizer 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer():\n",
    "    def __init__(self):\n",
    "        self.word_dict = {'oov': 0}\n",
    "        self.fit_checker = False\n",
    "  \n",
    "    def preprocessing(self, sequences):\n",
    "        result = []\n",
    "        for sent in sequences:\n",
    "            result.append(re.sub(\"[^a-zA-Z0-9]\", \" \", sent).lower().split())\n",
    "        return result\n",
    "  \n",
    "    def fit(self, sequences):\n",
    "        self.fit_checker = False\n",
    "        for sentence in self.preprocessing(sequences):\n",
    "            for token in sentence:\n",
    "                if token not in self.word_dict:\n",
    "                    self.word_dict[token] = len(self.word_dict)\n",
    "\n",
    "        self.fit_checker = True\n",
    "  \n",
    "    def transform(self, sequences):\n",
    "        result = []\n",
    "        tokens = self.preprocessing(sequences)\n",
    "        if self.fit_checker:\n",
    "            for sentence in tokens:\n",
    "                index = [self.word_dict[token] if token in self.word_dict else 0 for token in sentence]\n",
    "                result.append(index)\n",
    "            return result\n",
    "        else:\n",
    "            raise Exception(\"Tokenizer instance is not fitted yet.\")\n",
    "      \n",
    "    def fit_transform(self, sequences):\n",
    "        self.fit(sequences)\n",
    "        result = self.transform(sequences)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 문제 2) TfidfVectorizer 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TfidfVectorizer:\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.fit_checker = False\n",
    "  \n",
    "    def fit(self, sequences):\n",
    "        tokenized = self.tokenizer.fit_transform(sequences)\n",
    "        token_num = len(self.tokenizer.word_dict)-1\n",
    "        self.idf_matrix = []\n",
    "        for token in range(1, token_num+1):\n",
    "            df = sum([1 if token in sentence else 0 for sentence in tokenized])\n",
    "            self.idf_matrix.append(math.log(len(tokenized)/(1+df)))\n",
    "        \n",
    "        self.fit_checker = True\n",
    "\n",
    "    def transform(self, sequences):\n",
    "        if self.fit_checker:\n",
    "            tokenized = self.tokenizer.transform(sequences)\n",
    "            sentence_num = len(tokenized)\n",
    "            token_num = len(self.tokenizer.word_dict)-1\n",
    "            tfidf_list = []\n",
    "            for sentence in tokenized:\n",
    "                for token in range(1, token_num+1):\n",
    "                    tf = sentence.count(token)\n",
    "                    tfidf_list.append(tf * self.idf_matrix[token-1])\n",
    "            self.tfidf_matrix = np.reshape(tfidf_list, (sentence_num, token_num)).tolist()\n",
    "            return self.tfidf_matrix\n",
    "        else:\n",
    "            raise Exception(\"TfidfVectorizer instance is not fitted yet.\")\n",
    "\n",
    "    def fit_transform(self, sequences):\n",
    "        self.fit(sequences)\n",
    "        return self.transform(sequences)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "793d4bdf4aa091947cd8281459d6e8fe833d5ec676b0ac200c31417438349ef7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('condaenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
